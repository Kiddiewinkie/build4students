<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Face Emotion Detector</title>
    <script defer src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            padding: 20px;
        }

        .container {
            background: white;
            border-radius: 20px;
            padding: 40px;
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
            text-align: center;
            max-width: 900px;
            width: 100%;
        }

        h1 {
            color: #333;
            margin-bottom: 30px;
            font-size: 2.5em;
        }

        #startButton {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            border: none;
            padding: 15px 40px;
            font-size: 1.2em;
            border-radius: 50px;
            cursor: pointer;
            transition: transform 0.2s, box-shadow 0.2s;
            margin-bottom: 30px;
        }

        #startButton:hover {
            transform: translateY(-2px);
            box-shadow: 0 10px 20px rgba(102, 126, 234, 0.4);
        }

        #startButton:active {
            transform: translateY(0);
        }

        #startButton:disabled {
            opacity: 0.6;
            cursor: not-allowed;
        }

        .video-container {
            position: relative;
            display: none;
            margin: 0 auto 30px;
            max-width: 640px;
        }

        .video-container.active {
            display: block;
        }

        #video {
            width: 100%;
            height: auto;
            border-radius: 15px;
            transform: scaleX(-1);
        }

        #canvas {
            position: absolute;
            top: 0;
            left: 0;
        }

        .emotions-display {
            display: none;
            background: #f8f9fa;
            border-radius: 15px;
            padding: 25px;
            margin-top: 20px;
        }

        .emotions-display.active {
            display: block;
        }

        .emotion-item {
            display: flex;
            align-items: center;
            margin: 12px 0;
            padding: 10px;
            background: white;
            border-radius: 10px;
            box-shadow: 0 2px 5px rgba(0, 0, 0, 0.1);
        }

        .emotion-label {
            font-weight: 600;
            color: #555;
            width: 120px;
            text-align: left;
            font-size: 1.1em;
        }

        .emotion-bar-container {
            flex: 1;
            height: 24px;
            background: #e9ecef;
            border-radius: 12px;
            overflow: hidden;
            margin: 0 15px;
        }

        .emotion-bar {
            height: 100%;
            background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
            border-radius: 12px;
            transition: width 0.3s ease;
        }

        .emotion-value {
            font-weight: 600;
            color: #667eea;
            min-width: 50px;
            text-align: right;
        }

        .status {
            margin-top: 20px;
            padding: 15px;
            border-radius: 10px;
            font-size: 0.95em;
        }

        .status.loading {
            background: #fff3cd;
            color: #856404;
        }

        .status.error {
            background: #f8d7da;
            color: #721c24;
        }

        .status.success {
            background: #d4edda;
            color: #155724;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üé≠ Face Emotion Detector</h1>
        <button id="startButton">Start Camera</button>
        
        <div class="video-container" id="videoContainer">
            <video id="video" autoplay muted playsinline></video>
            <canvas id="canvas"></canvas>
        </div>

        <div class="emotions-display" id="emotionsDisplay">
            <div class="emotion-item">
                <div class="emotion-label">üòä Happy</div>
                <div class="emotion-bar-container">
                    <div class="emotion-bar" id="bar-happy"></div>
                </div>
                <div class="emotion-value" id="val-happy">0%</div>
            </div>
            <div class="emotion-item">
                <div class="emotion-label">üò¢ Sad</div>
                <div class="emotion-bar-container">
                    <div class="emotion-bar" id="bar-sad"></div>
                </div>
                <div class="emotion-value" id="val-sad">0%</div>
            </div>
            <div class="emotion-item">
                <div class="emotion-label">üò† Angry</div>
                <div class="emotion-bar-container">
                    <div class="emotion-bar" id="bar-angry"></div>
                </div>
                <div class="emotion-value" id="val-angry">0%</div>
            </div>
            <div class="emotion-item">
                <div class="emotion-label">üò≤ Surprised</div>
                <div class="emotion-bar-container">
                    <div class="emotion-bar" id="bar-surprised"></div>
                </div>
                <div class="emotion-value" id="val-surprised">0%</div>
            </div>
            <div class="emotion-item">
                <div class="emotion-label">üò® Fearful</div>
                <div class="emotion-bar-container">
                    <div class="emotion-bar" id="bar-fearful"></div>
                </div>
                <div class="emotion-value" id="val-fearful">0%</div>
            </div>
            <div class="emotion-item">
                <div class="emotion-label">ü§¢ Disgusted</div>
                <div class="emotion-bar-container">
                    <div class="emotion-bar" id="bar-disgusted"></div>
                </div>
                <div class="emotion-value" id="val-disgusted">0%</div>
            </div>
            <div class="emotion-item">
                <div class="emotion-label">üòê Neutral</div>
                <div class="emotion-bar-container">
                    <div class="emotion-bar" id="bar-neutral"></div>
                </div>
                <div class="emotion-value" id="val-neutral">0%</div>
            </div>
        </div>

        <div id="status"></div>
    </div>

    <script>
        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const startButton = document.getElementById('startButton');
        const videoContainer = document.getElementById('videoContainer');
        const emotionsDisplay = document.getElementById('emotionsDisplay');
        const statusDiv = document.getElementById('status');

        let modelsLoaded = false;
        let stream = null;

        function showStatus(message, type) {
            statusDiv.textContent = message;
            statusDiv.className = `status ${type}`;
        }

        async function loadModels() {
            try {
                showStatus('Loading AI models... This may take a moment.', 'loading');
                
                const MODEL_URL = 'https://cdn.jsdelivr.net/npm/@vladmandic/face-api@1.7.12/model';
                
                await faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL);
                await faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL);
                
                modelsLoaded = true;
                showStatus('Models loaded successfully! Click "Start Camera" to begin.', 'success');
                startButton.disabled = false;
            } catch (error) {
                showStatus('Error loading models: ' + error.message, 'error');
                console.error('Model loading error:', error);
            }
        }

        async function startVideo() {
            try {
                stream = await navigator.mediaDevices.getUserMedia({ 
                    video: { 
                        width: { ideal: 640 },
                        height: { ideal: 480 }
                    } 
                });
                video.srcObject = stream;
                
                video.addEventListener('loadedmetadata', () => {
                    canvas.width = video.videoWidth;
                    canvas.height = video.videoHeight;
                    videoContainer.classList.add('active');
                    emotionsDisplay.classList.add('active');
                    startButton.textContent = 'Stop Camera';
                    showStatus('Camera active. Detecting emotions...', 'success');
                    detectEmotions();
                });
            } catch (error) {
                showStatus('Error accessing camera: ' + error.message, 'error');
                console.error('Camera error:', error);
            }
        }

        function stopVideo() {
            if (stream) {
                stream.getTracks().forEach(track => track.stop());
                video.srcObject = null;
                videoContainer.classList.remove('active');
                emotionsDisplay.classList.remove('active');
                startButton.textContent = 'Start Camera';
                showStatus('Camera stopped.', 'success');
            }
        }

        async function detectEmotions() {
            if (!video.srcObject) return;

            const detections = await faceapi
                .detectSingleFace(video, new faceapi.TinyFaceDetectorOptions())
                .withFaceExpressions();

            const ctx = canvas.getContext('2d');
            ctx.clearRect(0, 0, canvas.width, canvas.height);

            if (detections) {
                const expressions = detections.expressions;
                
                // Update emotion bars and values
                Object.keys(expressions).forEach(emotion => {
                    const value = Math.round(expressions[emotion] * 100);
                    const bar = document.getElementById(`bar-${emotion}`);
                    const val = document.getElementById(`val-${emotion}`);
                    
                    if (bar && val) {
                        bar.style.width = `${value}%`;
                        val.textContent = `${value}%`;
                    }
                });

                // Draw face detection box (flip horizontally to match mirrored video)
                const box = detections.detection.box;
                const flippedX = canvas.width - box.x - box.width;
                
                ctx.strokeStyle = '#667eea';
                ctx.lineWidth = 3;
                ctx.strokeRect(flippedX, box.y, box.width, box.height);

                // Find dominant emotion
                const dominantEmotion = Object.keys(expressions).reduce((a, b) => 
                    expressions[a] > expressions[b] ? a : b
                );
                
                // Draw emotion label (also flipped)
                ctx.fillStyle = '#667eea';
                ctx.font = 'bold 20px Arial';
                ctx.fillText(dominantEmotion.toUpperCase(), flippedX, box.y - 10);
            }

            requestAnimationFrame(detectEmotions);
        }

        startButton.addEventListener('click', () => {
            if (!modelsLoaded) {
                showStatus('Please wait for models to load first.', 'error');
                return;
            }

            if (video.srcObject) {
                stopVideo();
            } else {
                startVideo();
            }
        });

        // Load models on page load
        window.addEventListener('load', () => {
            startButton.disabled = true;
            loadModels();
        });
    </script>
</body>
</html>
